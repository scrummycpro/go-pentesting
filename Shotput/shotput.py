from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import sys
import argparse
from urllib.parse import urlparse, quote
from concurrent.futures import ThreadPoolExecutor


def take_screenshot(url):
    # Set up Chrome options for headless mode
    chrome_options = Options()
    chrome_options.add_argument('--headless')  # Run Chrome in headless mode (no GUI)
    chrome_options.add_argument('--no-sandbox')  # Bypass OS security model

    # Initialize Chrome webdriver
    driver = webdriver.Chrome(options=chrome_options)

    # Navigate to the URL
    driver.get(url)

    # Wait for the page to load (you can adjust the sleep time if needed)
    time.sleep(5)

    # Extract the domain name and path from the URL
    parsed_url = urlparse(url)
    domain = parsed_url.netloc
    path = quote(parsed_url.path)  # Replace special characters with percent encoding

    # Concatenate domain and path, and remove any leading/trailing slashes
    filename = f"{domain.rstrip('/')}_{path.lstrip('/')}"

    # Generate output filename
    output_filename = f"{filename}_screenshot.png"

    # Take screenshot and save to file
    driver.save_screenshot(output_filename)

    # Close the webdriver
    driver.quit()

    print(f'Screenshot saved as {output_filename}')

def capture_screenshots(urls):
    # Use ThreadPoolExecutor to capture screenshots in parallel
    with ThreadPoolExecutor() as executor:
        executor.map(take_screenshot, urls)

if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Capture screenshots of web pages')
    parser.add_argument('urls', metavar='URL', type=str, nargs='+',
                        help='URLs to capture screenshots for')
    args = parser.parse_args()

    # Capture screenshots for the specified URLs
    capture_screenshots(args.urls)
